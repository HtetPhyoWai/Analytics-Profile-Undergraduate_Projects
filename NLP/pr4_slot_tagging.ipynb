{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pr4_slot_tagging.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"qiutsq9BqzNL","colab_type":"code","colab":{}},"source":["#Htet Phyo Wai\n","#Progress Report 3/4 Implementation\n","#4/30/19\n","\n","#(Note :: The program is adapted from Microsoft Online Learning on NLP using RNN models and uses ATIS(Air Travel Information Services) Test Data \n","#https://github.com/Microsoft/CNTK/tree/v2.0/Examples/LanguageUnderstanding/ATIS/Data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cyvTD-L60F9b","colab_type":"text"},"source":["##**Slot Tagging using Neural Networks**\n","\n","In this methods, we select individual words and tags to the respective classes. \n","\n","Classes are provided as labels in the training data set. \n","\n","The following techniques and network models are used in the process of slots tagging:\n","\n","- LSTM: It is composed of the following stages :\n","\n","    1. New memory generation: A new memory (h(t)) is the consolidation of a new input word x(t) with the past hidden state h(t−1)\n","\n","    2. Input Gate: The input gate uses the input word and the past hidden state to determine whether or not the input is worth preserving and thus is used to gate the new memory. It thus produces it as an indicator of this information.\n","    \n","    3. Forget Gate: This gate is similar to the input gate except that it does not make a determination of usefulness of the input word – instead it makes an assessment on whether the past memory cell is useful for the computation of the current memory cell. Thus, the forget gate looks at the input word and the past hidden state and produces f(t).\n","\n","    4. Final memory generation: This stage first takes the advice of the forget gate f(t) and accordingly forgets the past memory c(t−1). Similarly, it takes the advice of the input gate it and accordingly gates the new memory c ̃(t). It then sums these two results to produce the final memory c(t).\n","\n","    5. Output/Exposure Gate: to separate the final memory from the hidden state. The final memory c(t) contains a lot of information that is not necessarily required to be saved in the hidden state. Hidden states are used in every single gate of an LSTM and thus, this gate makes the assessment regarding what parts of the memory c(t) needs to be exposed/present in the hidden state h(t). The signal it produces to indicate this is ot and this is used to gate the point-wise tanh of the memory.\n","\n","<br>\n","<br>\n","\n"]},{"cell_type":"code","metadata":{"id":"8HkXH9Raieus","colab_type":"code","colab":{}},"source":["!apt-get install --no-install-recommends openmpi-bin libopenmpi-dev libopencv-dev python3-opencv python-opencv && ln -sf /usr/lib/x86_64-linux-gnu/libmpi_cxx.so /usr/lib/x86_64-linux-gnu/libmpi_cxx.so.1 && ln -sf /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so.12 && ln -sf /usr/lib/x86_64-linux-gnu/libmpi.so /usr/lib/x86_64-linux-gnu/libmpi.so.12 && pip install cntk\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dsShSvfZrGhJ","colab_type":"code","colab":{}},"source":["import math\n","import numpy as np\n","import cntk as C"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tmjV0ar3ioU_","colab_type":"code","outputId":"972cf756-47a9-41ad-b4dc-30055665bfbd","executionInfo":{"status":"ok","timestamp":1556683083242,"user_tz":300,"elapsed":7331,"user":{"displayName":"Htet Phyo Wai","photoUrl":"","userId":"09751684198621225603"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\n","import requests\n","import os\n","\n","def download(url, filename):\n","    \"\"\" utility function to download a file \"\"\"\n","    response = requests.get(url, stream=True)\n","    with open(filename, \"wb\") as handle:\n","        for data in response.iter_content():\n","            handle.write(data)\n","\n","locations = ['Tutorials/SLUHandsOn', 'Examples/LanguageUnderstanding/ATIS/BrainScript']\n","\n","data = {\n","  'train': { 'file': 'atis.train.ctf', 'location': 0 },\n","  'test': { 'file': 'atis.test.ctf', 'location': 0 },\n","  'query': { 'file': 'query.wl', 'location': 1 },\n","  'slots': { 'file': 'slots.wl', 'location': 1 }\n","}\n","\n","for item in data.values():\n","    location = locations[item['location']]\n","    path = os.path.join('..', location, item['file'])\n","    if os.path.exists(path):\n","        print(\"Reusing locally cached:\", item['file'])\n","        # Update path\n","        item['file'] = path\n","    elif os.path.exists(item['file']):\n","        print(\"Reusing locally cached:\", item['file'])\n","    else:\n","        print(\"Starting download:\", item['file'])\n","        url = \"https://github.com/Microsoft/CNTK/blob/v2.0/%s/%s?raw=true\"%(location, item['file'])\n","        download(url, item['file'])\n","        print(\"Download completed\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Starting download: atis.train.ctf\n","Download completed\n","Starting download: atis.test.ctf\n","Download completed\n","Starting download: query.wl\n","Download completed\n","Starting download: slots.wl\n","Download completed\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iKWD34alrGmy","colab_type":"code","colab":{}},"source":["# number of words in vocab, slot labels, and intent labels\n","vocab_size = 943 ; num_labels = 129 ; num_intents = 26    \n","\n","# model dimensions\n","input_dim  = vocab_size\n","label_dim  = num_labels\n","emb_dim    = 150\n","hidden_dim = 300\n","\n","# Create the containers for input feature (x) and the label (y)\n","x = C.sequence.input_variable(vocab_size)\n","y = C.sequence.input_variable(num_labels)\n","\n","def create_model():\n","    with C.layers.default_options(initial_state=0.1):\n","        return C.layers.Sequential([\n","            C.layers.Embedding(emb_dim, name='embed'),\n","            C.layers.Recurrence(C.layers.LSTM(hidden_dim), go_backwards=False),\n","            C.layers.Dense(num_labels, name='classify')\n","        ])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"anXNhVAJrGqD","colab_type":"code","outputId":"a97ca43e-da39-4312-8b8e-25f542648d01","executionInfo":{"status":"ok","timestamp":1556683087181,"user_tz":300,"elapsed":314,"user":{"displayName":"Htet Phyo Wai","photoUrl":"","userId":"09751684198621225603"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["# peek\n","z = create_model()\n","print(z.embed.E.shape)\n","print(z.classify.b.value)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(-1, 150)\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RwetnZ27rBQQ","colab_type":"code","outputId":"33ef3b50-02ba-45bd-b382-798804147bbc","executionInfo":{"status":"ok","timestamp":1556683089076,"user_tz":300,"elapsed":275,"user":{"displayName":"Htet Phyo Wai","photoUrl":"","userId":"09751684198621225603"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Pass an input and check the dimension\n","z = create_model()\n","print(z(x).embed.E.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(943, 150)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mBbpN82_rBSt","colab_type":"code","colab":{}},"source":["def create_reader(path, is_training):\n","    return C.io.MinibatchSource(C.io.CTFDeserializer(path, C.io.StreamDefs(\n","         query         = C.io.StreamDef(field='S0', shape=vocab_size,  is_sparse=True),\n","         intent_unused = C.io.StreamDef(field='S1', shape=num_intents, is_sparse=True),  \n","         slot_labels   = C.io.StreamDef(field='S2', shape=num_labels,  is_sparse=True)\n","     )), randomize=is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HsGAII7ZrBVO","colab_type":"code","outputId":"12934b27-1563-4578-ceea-42d2dfc97da3","executionInfo":{"status":"ok","timestamp":1556683091582,"user_tz":300,"elapsed":371,"user":{"displayName":"Htet Phyo Wai","photoUrl":"","userId":"09751684198621225603"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# peek\n","reader = create_reader(data['train']['file'], is_training=True)\n","reader.streams.keys()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['slot_labels', 'query', 'intent_unused'])"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"lEbij1yfrBXy","colab_type":"code","outputId":"146c894e-439f-4bfd-c000-2dced742a0dc","executionInfo":{"status":"ok","timestamp":1556683092462,"user_tz":300,"elapsed":358,"user":{"displayName":"Htet Phyo Wai","photoUrl":"","userId":"09751684198621225603"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["def create_criterion_function(model):\n","    labels = C.placeholder(name='labels')\n","    ce   = C.cross_entropy_with_softmax(model, labels)\n","    errs = C.classification_error      (model, labels)\n","    return C.combine ([ce, errs]) # (features, labels) -> (loss, metric)\n","\n","criterion = create_criterion_function(create_model())\n","criterion.replace_placeholders({criterion.placeholders[0]: C.sequence.input_variable(num_labels)})"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Composite(Combine): Input('Input2300', [#, *], [129]), Placeholder('labels', [???], [???]) -> Output('Block2270_Output_0', [#, *], [???]), Output('Block2290_Output_0', [#, *], [???])"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"Jzf-anWTrBaA","colab_type":"code","colab":{}},"source":["def create_criterion_function_preferred(model, labels):\n","    ce   = C.cross_entropy_with_softmax(model, labels)\n","    errs = C.classification_error      (model, labels)\n","    return ce, errs # (model, labels) -> (loss, error metric)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x2wn9CoIrBci","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1C0YImzDrBfQ","colab_type":"code","colab":{}},"source":["def train(reader, model_func, max_epochs=10):\n","    \n","    # Instantiate the model function; x is the input (feature) variable \n","    model = model_func(x)\n","    \n","    # Instantiate the loss and error function\n","    loss, label_error = create_criterion_function_preferred(model, y)\n","\n","    # training conf\n","    epoch_size = 18000        # half the dataset size \n","    minibatch_size = 70\n","    \n","    # LR schedule over epochs \n","    lr_per_sample = [0.003]*4+[0.0015]*24+[0.0003]\n","    lr_per_minibatch = [lr * minibatch_size for lr in lr_per_sample]\n","    lr_schedule = C.learning_rate_schedule(lr_per_minibatch, C.UnitType.minibatch, epoch_size)\n","    \n","    # Momentum schedule\n","    momentum_as_time_constant = C.momentum_as_time_constant_schedule(700)\n","    \n","\n","\n","    learner = C.adam(parameters=model.parameters,\n","                     lr=lr_schedule,\n","                     momentum=momentum_as_time_constant,\n","                     gradient_clipping_threshold_per_sample=15, \n","                     gradient_clipping_with_truncation=True)\n","\n","    # Setup the progress updater\n","    progress_printer = C.logging.ProgressPrinter(tag='Training', num_epochs=max_epochs)\n","    \n","       # Instantiate the trainer\n","    trainer = C.Trainer(model, (loss, label_error), learner, progress_printer)\n","\n","    # process minibatches and perform model training\n","    C.logging.log_number_of_parameters(model)\n","\n","    t = 0\n","    for epoch in range(max_epochs):         # loop over epochs\n","        epoch_end = (epoch+1) * epoch_size\n","        while t < epoch_end:                # loop over minibatches on the epoch\n","            data = reader.next_minibatch(minibatch_size, input_map={  # fetch minibatch\n","                x: reader.streams.query,\n","                y: reader.streams.slot_labels\n","            })\n","            trainer.train_minibatch(data)               # update model with it\n","            t += data[y].num_samples                    # samples \n","        trainer.summarize_training_progress()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oHw-HDK0rBhc","colab_type":"code","outputId":"47b77e0f-e13b-4281-e60d-0189b9be75a2","executionInfo":{"status":"ok","timestamp":1556683191338,"user_tz":300,"elapsed":73394,"user":{"displayName":"Htet Phyo Wai","photoUrl":"","userId":"09751684198621225603"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["def do_train():\n","    global z\n","    z = create_model()\n","    reader = create_reader(data['train']['file'], is_training=True)\n","    train(reader, z)\n","do_train()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training 721479 parameters in 6 parameter tensors.\n","Learning rate per minibatch: 0.21\n","Finished Epoch[1 of 10]: [Training] loss = 0.692392 * 18010, metric = 14.14% * 18010 7.114s (2531.6 samples/s);\n","Finished Epoch[2 of 10]: [Training] loss = 0.196765 * 18051, metric = 4.42% * 18051 7.240s (2493.2 samples/s);\n","Finished Epoch[3 of 10]: [Training] loss = 0.127771 * 17941, metric = 2.88% * 17941 7.039s (2548.8 samples/s);\n","Finished Epoch[4 of 10]: [Training] loss = 0.088850 * 18059, metric = 2.11% * 18059 7.159s (2522.6 samples/s);\n","Learning rate per minibatch: 0.105\n","Finished Epoch[5 of 10]: [Training] loss = 0.056562 * 17957, metric = 1.36% * 17957 7.402s (2426.0 samples/s);\n","Finished Epoch[6 of 10]: [Training] loss = 0.052673 * 18021, metric = 1.27% * 18021 7.404s (2434.0 samples/s);\n","Finished Epoch[7 of 10]: [Training] loss = 0.047527 * 17980, metric = 1.23% * 17980 7.207s (2494.8 samples/s);\n","Finished Epoch[8 of 10]: [Training] loss = 0.043071 * 18025, metric = 1.12% * 18025 7.398s (2436.5 samples/s);\n","Finished Epoch[9 of 10]: [Training] loss = 0.030572 * 17956, metric = 0.84% * 17956 7.621s (2356.1 samples/s);\n","Finished Epoch[10 of 10]: [Training] loss = 0.032606 * 18039, metric = 0.84% * 18039 7.509s (2402.3 samples/s);\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nUmZ7yQHrBkd","colab_type":"code","colab":{}},"source":["def evaluate(reader, model_func):\n","    \n","    # Instantiate the model function; x is the input (feature) variable \n","    model = model_func(x)\n","    \n","    # Create the loss and error functions\n","    loss, label_error = create_criterion_function_preferred(model, y)\n","\n","    # process minibatches and perform evaluation\n","    progress_printer = C.logging.ProgressPrinter(tag='Evaluation', num_epochs=0)\n","\n","    while True:\n","        minibatch_size = 500\n","        data = reader.next_minibatch(minibatch_size, input_map={  # fetch minibatch\n","            x: reader.streams.query,\n","            y: reader.streams.slot_labels\n","        })\n","        if not data:                                 # until we hit the end\n","            break\n","\n","        evaluator = C.eval.Evaluator(loss, progress_printer)\n","        evaluator.test_minibatch(data)\n","     \n","    evaluator.summarize_test_progress()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hjKW5w0nsFEf","colab_type":"code","outputId":"960825c5-44e0-4485-8f41-0ae73943a6b9","executionInfo":{"status":"ok","timestamp":1556683207937,"user_tz":300,"elapsed":1387,"user":{"displayName":"Htet Phyo Wai","photoUrl":"","userId":"09751684198621225603"}},"colab":{"base_uri":"https://localhost:8080/","height":476}},"source":["def do_test():\n","    reader = create_reader(data['test']['file'], is_training=False)\n","    evaluate(reader, z)\n","do_test()\n","z.classify.b.value"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Finished Evaluation [1]: Minibatch[1-23]: metric = 0.27% * 10984;\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([-0.03935637, -0.09902153, -0.03894174, -0.03529919, -0.01363602,\n","       -0.05434954, -0.04320217, -0.10497631, -0.02455624, -0.05959513,\n","       -0.03621629, -0.04268409, -0.05343723, -0.06117778, -0.08973555,\n","       -0.07753321, -0.12392411, -0.04092873,  0.04135334, -0.13623148,\n","       -0.08145326, -0.05778902,  0.01750098, -0.01237598, -0.04901759,\n","       -0.00611704, -0.03405998,  0.00117075, -0.01631831, -0.04836401,\n","       -0.03489719, -0.02382404, -0.08001239, -0.00699768, -0.05259896,\n","        0.0855659 ,  0.06091429, -0.0171707 , -0.01988967, -0.05222796,\n","       -0.14214335, -0.0557886 ,  0.0151703 , -0.04353099,  0.01414575,\n","       -0.08254308,  0.01819646,  0.03762412,  0.0261627 , -0.0337337 ,\n","       -0.05364189, -0.08558379,  0.03114999, -0.06602737,  0.05271252,\n","        0.00680154, -0.04858708, -0.05499237, -0.05703288, -0.05267509,\n","       -0.01114069, -0.05643699,  0.02559835, -0.02465305, -0.03254724,\n","       -0.04454485, -0.10612184, -0.05292601, -0.05991152, -0.12081891,\n","       -0.08207239, -0.06330864, -0.044547  , -0.04293084, -0.06758358,\n","        0.01398879, -0.00640239,  0.03188937, -0.01051881, -0.04581322,\n","       -0.03509152, -0.00274806, -0.01621265, -0.11960274, -0.02629076,\n","       -0.0587104 , -0.08101686, -0.0100819 , -0.09632041, -0.09208703,\n","       -0.02963087,  0.00039938, -0.09323493, -0.10820019, -0.04707254,\n","       -0.09954007,  0.07396802, -0.02589222, -0.08307762, -0.07465759,\n","        0.02455412, -0.08676111, -0.07357937, -0.08875261, -0.03529109,\n","        0.04303169, -0.12154242, -0.05336315, -0.07821185, -0.00103176,\n","       -0.0625988 , -0.04716474, -0.00549289, -0.02909018,  0.0175648 ,\n","       -0.06075686,  0.00933618, -0.04991724, -0.02055197, -0.13849476,\n","       -0.12041414, -0.04748277, -0.08404006, -0.00554012,  0.0074841 ,\n","       -0.03631065, -0.03949322, -0.07358279,  0.10652625], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"r-lYqsoIsFBl","colab_type":"code","outputId":"c6b11f26-95a3-4262-bffe-230c0beba6eb","executionInfo":{"status":"ok","timestamp":1556683209554,"user_tz":300,"elapsed":278,"user":{"displayName":"Htet Phyo Wai","photoUrl":"","userId":"09751684198621225603"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# load dictionaries\n","query_wl = [line.rstrip('\\n') for line in open(data['query']['file'])]\n","slots_wl = [line.rstrip('\\n') for line in open(data['slots']['file'])]\n","query_dict = {query_wl[i]:i for i in range(len(query_wl))}\n","slots_dict = {slots_wl[i]:i for i in range(len(slots_wl))}\n","\n","# let's run a sequence through\n","seq = 'BOS flights from new york to seattle EOS'\n","w = [query_dict[w] for w in seq.split()] # convert to word indices\n","print(w)\n","onehot = np.zeros([len(w),len(query_dict)], np.float32)\n","for t in range(len(w)):\n","    onehot[t,w[t]] = 1\n","\n","#x = C.sequence.input_variable(vocab_size)\n","pred = z(x).eval({x:[onehot]})[0]\n","print(pred.shape)\n","best = np.argmax(pred,axis=1)\n","print(best)\n","list(zip(seq.split(),[slots_wl[s] for s in best]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[178, 429, 444, 619, 937, 851, 752, 179]\n","(8, 129)\n","[128 128 128  48 110 128  78 128]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[('BOS', 'O'),\n"," ('flights', 'O'),\n"," ('from', 'O'),\n"," ('new', 'B-fromloc.city_name'),\n"," ('york', 'I-fromloc.city_name'),\n"," ('to', 'O'),\n"," ('seattle', 'B-toloc.city_name'),\n"," ('EOS', 'O')]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"M7gh6wgZsE-z","colab_type":"code","outputId":"188473e2-80a1-4fb9-aeab-6c40200e2459","executionInfo":{"status":"ok","timestamp":1556683292280,"user_tz":300,"elapsed":80443,"user":{"displayName":"Htet Phyo Wai","photoUrl":"","userId":"09751684198621225603"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["def create_model():\n","    with C.layers.default_options(initial_state=0.1):\n","        return C.layers.Sequential([\n","            C.layers.Embedding(emb_dim),\n","            C.layers.BatchNormalization(),\n","            C.layers.Recurrence(C.layers.LSTM(hidden_dim), go_backwards=False),\n","            C.layers.BatchNormalization(),\n","            C.layers.Dense(num_labels)\n","        ])\n","\n","do_train()\n","do_test()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training 722379 parameters in 10 parameter tensors.\n","Learning rate per minibatch: 0.21\n","Finished Epoch[1 of 10]: [Training] loss = 0.382122 * 18010, metric = 7.10% * 18010 7.644s (2356.1 samples/s);\n","Finished Epoch[2 of 10]: [Training] loss = 0.152723 * 18051, metric = 3.12% * 18051 7.574s (2383.3 samples/s);\n","Finished Epoch[3 of 10]: [Training] loss = 0.102781 * 17941, metric = 2.21% * 17941 7.677s (2337.0 samples/s);\n","Finished Epoch[4 of 10]: [Training] loss = 0.083122 * 18059, metric = 1.88% * 18059 7.925s (2278.7 samples/s);\n","Learning rate per minibatch: 0.105\n","Finished Epoch[5 of 10]: [Training] loss = 0.040701 * 17957, metric = 0.96% * 17957 8.091s (2219.4 samples/s);\n","Finished Epoch[6 of 10]: [Training] loss = 0.041964 * 18021, metric = 1.00% * 18021 8.027s (2245.0 samples/s);\n","Finished Epoch[7 of 10]: [Training] loss = 0.037129 * 17980, metric = 0.98% * 17980 7.938s (2265.1 samples/s);\n","Finished Epoch[8 of 10]: [Training] loss = 0.028060 * 18025, metric = 0.73% * 18025 7.931s (2272.7 samples/s);\n","Finished Epoch[9 of 10]: [Training] loss = 0.016955 * 17956, metric = 0.53% * 17956 7.987s (2248.2 samples/s);\n","Finished Epoch[10 of 10]: [Training] loss = 0.020623 * 18039, metric = 0.60% * 18039 7.951s (2268.8 samples/s);\n","Finished Evaluation [1]: Minibatch[1-23]: metric = 0.41% * 10984;\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LovApVg2sE8K","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0tTZsBeErBm8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EPAjLCWcrBpt","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SZ5YGtlWrBsd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}